import speech_recognition as sr
import google.generativeai as genai
from typing import List, Dict, Optional, Any
import json
from kokoro import KPipeline
import sounddevice as sd
import numpy as np
import pyttsx3  # Import pyttsx3 for fallback TTS
# Corrected imports for Wav2Vec2
from transformers import AutoProcessor, AutoModelForCTC
import sys  # Import sys for graceful exit
import noisereduce as nr  # Import noisereduce
import logging  # Import logging

# --- Logging Setup ---
logging.basicConfig(level=logging.INFO,
                    format='%(asctime)s - %(levelname)s - %(message)s')

# --- Configuration ---
# Removed for security to load via system variable
GOOGLE_API_KEY = ""
# GOOGLE_API_KEY = os.environ.get("GOOGLE_API_KEY")  # Secure way, load from environment variable

if not GOOGLE_API_KEY:
    print("Warning: GOOGLE_API_KEY environment variable not set. Gemini API might not work.")
    USE_GEMINI = False  # Disable Gemini usage if key is missing
else:
    USE_GEMINI = True
    genai.configure(api_key=GOOGLE_API_KEY)
    generation_config = genai.GenerationConfig(
        temperature=0.3,  # Lower temperature for more predictable JSON output
        top_p=0.9,
        top_k=20,  # Reduced k for more focused responses
    )
    safety_settings = [
        {"category": "HARM_CATEGORY_HARASSMENT",
            "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
        {"category": "HARM_CATEGORY_HATE_SPEECH",
            "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
        {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT",
            "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
        {"category": "HARM_CATEGORY_DANGEROUS_CONTENT",
            "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
    ]
    model = genai.GenerativeModel(model_name="gemini-2.0-flash-lite",  # Use flash-lite model as requested
                                  generation_config=generation_config,
                                  safety_settings=safety_settings)

# Initialize kokoro pipeline for TTS
try:
    # 'a' likely means auto-detect language, adjust if needed
    tts_pipeline = KPipeline(lang_code='a')
except Exception as e:
    print(f"Error initializing kokoro TTS pipeline: {e}")
    print("Falling back to basic pyttsx3 TTS. Ensure kokoro and its dependencies are installed correctly.")
    USE_KOKORO_TTS = False
    engine = pyttsx3.init()  # Initialize pyttsx3 as fallback
else:
    USE_KOKORO_TTS = True
    engine = None  # No need for pyttsx3 engine if kokoro is working

# --- Initialize OpenAI Whisper for STT ---
try:
    whisper_processor = AutoProcessor.from_pretrained(
        "mesolitica/wav2vec2-xls-r-300m-mixed")
    whisper_model = AutoModelForCTC.from_pretrained(
        "mesolitica/wav2vec2-xls-r-300m-mixed")
    USE_WHISPER_STT = True
    print("OpenAI Whisper STT initialized.")
except Exception as e:
    print(f"Error initializing OpenAI Whisper: {e}")
    print("Falling back to Google Speech Recognition for STT.")
    USE_WHISPER_STT = False


# --- Text-to-Speech (TTS) ---
def text_to_speech(text: str):
    """Converts text to speech using kokoro (or fallback to pyttsx3)."""
    if USE_KOKORO_TTS:
        try:
            samples_generated = 0
            # To accumulate audio chunks
            full_audio = np.array([], dtype=np.float32)

            # Using 'af_bella' voice as per example
            # Using af_nicole voice. 'af_nicole' voice
            for _, _, audio in tts_pipeline(text, voice='bf_emma'):
                if audio is not None:  # audio could be None if there is an issue
                    samples = audio.shape[0]
                    if samples > 0:  # Ensure audio data is valid
                        samples_generated += samples
                        full_audio = np.concatenate(
                            (full_audio, audio))  # Accumulate audio
                    else:
                        print(
                            "Warning: No audio samples generated by kokoro for this chunk.")
                else:
                    print("Warning: No audio data returned by kokoro for this chunk.")

            if samples_generated == 0:
                print("Error: kokoro TTS pipeline did not generate any audio samples.")
                fallback_tts(text)  # Fallback to pyttsx3 if kokoro fails
            else:
                # --- AUDIO PLAYBACK using sounddevice ---
                # Assuming kokoro samplerate is 24kHz, check kokoro docs
                sd.play(full_audio, samplerate=24000)
                sd.wait()  # Wait until audio finishes playing

        except Exception as e:
            print(f"kokoro TTS Error: {e}")
            print("Falling back to basic pyttsx3 TTS.")
            fallback_tts(text)  # Fallback to pyttsx3 if kokoro fails
    else:
        fallback_tts(text)  # Directly use pyttsx3 if kokoro init failed


def fallback_tts(text: str):
    """Uses pyttsx3 for TTS as a fallback."""
    if engine:  # Check if pyttsx3 engine is initialized
        try:
            engine.say(text)
            engine.runAndWait()
        except Exception as e:
            print(f"Fallback pyttsx3 TTS Error: {e}")
            print("Error with both kokoro and pyttsx3 TTS. Please check your TTS setup.")
    else:
        print("Error: Both kokoro and pyttsx3 TTS failed to initialize.")
        print("Text-to-Speech will not work.")


# --- Speech-to-Text (STT) with LLM Context ---
def speech_to_text_with_intent(context_prompt: str = "") -> Optional[Dict[str, Any]]:
    """
    Captures audio from microphone, converts it to text using Whisper or Google STT,
    and uses LLM to get user intent in JSON format.
    """
    samplerate = 16000  # Consistent samplerate for both STT engines and noise reduction
    duration = 5  # Maximum recording duration in seconds
    print(f"Listening for {duration} seconds...")
    recording = sd.rec(int(samplerate * duration),
                       samplerate=samplerate, channels=1, dtype='float32')
    sd.wait()  # Wait until recording is finished
    audio_data = np.squeeze(recording)  # Remove single-channel dimension

    # --- Apply Noise Reduction ---
    try:
        reduced_noise = nr.reduce_noise(
            y=audio_data,
            sr=samplerate,
            # Example: Aggressive noise reduction (adjust this value)
            prop_decrease=0.9,
            time_constant_s=0.5,  # Example: Adjust time constant if needed
            # n_std_thresh=1.5     # REMOVED n_std_thresh
        )
        print("Noise reduction applied.")
        audio_for_stt = reduced_noise  # Use noise-reduced audio for STT

    except Exception as e:
        print(f"Error applying noise reduction: {e}")
        print("Continuing without noise reduction.")
        audio_for_stt = audio_data  # Fallback to original audio

    if USE_WHISPER_STT:
        # --- Use Whisper for STT ---
        print("Using OpenAI Whisper for Speech Recognition...")

        input_values = whisper_processor(
            audio_for_stt, sampling_rate=samplerate, return_tensors="pt").input_values
        logits = whisper_model(input_values).logits
        predicted_ids = np.argmax(logits.detach().cpu().numpy(), axis=-1)
        transcription = whisper_processor.batch_decode(
            predicted_ids, skip_special_tokens=True)[0]

        query = transcription
        print(f"Whisper Transcription: {query}")

        if not query.strip():  # Check for empty transcription (silence)
            print("Empty transcription (silence detected).")
            return {"intent": "silence"}  # Return "silence" intent

        if USE_GEMINI:
            language_prompt = f"""Identify the language of the following text.
            The text is transcribed by a speech-to-text model that is trained on Malay, Singlish, and Mandarin primarily, but may also transcribe other languages.
            Just return the language name. If you are unsure, return 'unknown'.

            Text: "{query}"
            Language: """
            try:
                response = model.generate_content(language_prompt)
                detected_language = response.text.strip()
                print(f"Detected Language: {detected_language}")
            except Exception as e:
                print(f"Error detecting language: {e}")
                detected_language = "unknown"  # Default to unknown on error
        else:
            # If no Gemini
            detected_language = "Language detection skipped (Gemini not enabled)."
    else:
        # --- Fallback to Google Speech Recognition ---
        print("Using Google Speech Recognition...")
        r = sr.Recognizer()

        # Convert NumPy array to AudioData for Google STT
        # Scale and convert to int16
        audio_int16 = (audio_for_stt * 32767).astype(np.int16)
        audio_bytes = audio_int16.tobytes()
        audio_data_sr = sr.AudioData(
            audio_bytes, samplerate=samplerate, sample_width=2)  # sample_width=2 for int16

        try:
            print("Recognizing...")
            # Auto language detection by Google STT
            query = r.recognize_google(audio_data_sr)
            print(f"Google STT User said: {query}\n")

        except sr.UnknownValueError:
            print("Could not understand audio (Google STT)")
            # No TTS prompt here for unknown, handled in main loop
            return {"intent": "unknown"}
        except sr.RequestError as e:
            print(
                f"Could not request results from Speech Recognition service (Google STT); {e}")
            # No TTS prompt here for error, handled in main loop
            return {"intent": "error"}

        if not query.strip():  # Check for empty transcription after Google STT
            print("Empty transcription (silence detected).")
            return {"intent": "silence"}  # Return "silence" intent

        # Assume English if using Google STT as it auto-detects
        detected_language = "English (Google STT)"

    user_text = query.lower()

    if USE_GEMINI:
        intent_prompt = f"""{context_prompt}
        Analyze the following user text from a Grab driver. Determine the user's intent related to ride bookings and general actions.
        Return a JSON object with 'intent' and optionally 'parameters'.
        If you cannot determine the intent, set intent to 'unknown'.

        **Key Intents:**

        1.  **Show Bookings Intent:** Use this intent when the user wants to see their ride bookings OR select a specific ride from a list. Do not shorten place names.
            - **Intent Name:** `"show_bookings"`
            - **Sub-intents and Parameters:**
                - **To show all bookings:** User phrases like "show me my bookings", "my bookings", "list my rides", "what are my bookings".
                - **To select a specific ride:** User phrases like "choose number one", "number 2 please", "I want ride 3", or destination names.
                - **Parameters:**  `"ride_index"` (integer, 1-indexed) OR `"destination"` (string, ride destination)

        2.  **Confirmation Intent:** User confirms an action (e.g., confirming a ride).
            - **Intent Name:** `"confirm"`
            - **Example User Phrases:** "yes", "confirm", "yep", "okay", "ok", "right"
            - **Example User Phrases (Negative - to avoid misclassification):** "what is the weather", "traffic please", "directions to somewhere"

        3.  **Decline Intent:** User declines an action (e.g., declining a ride).
            - **Intent Name:** `"decline"`

        4.  **Directions Intent (General):** User requests general directions.
            - **Intent Name:** `"directions"`

        5.  **Show Directions Intent (Ride-Related):** User wants to see directions for a specific booked ride.
            - **Intent Name:** `"show_directions"`

        6.  **Traffic Info Intent:** User requests traffic information.
            - **Intent Name:** `"traffic_info"`

        7.  **Weather Info Intent:** User requests weather information.
            - **Intent Name:** `"weather_info"`

        **Combined Intent Example:** User asks for both weather and traffic.
        If the user says "weather and traffic", return:
        ```json
        {{
          "intent": "combined_info",
          "parameters": {{
            "intents": ["weather_info", "traffic_info"]
          }}
        }}
        ```
        If the user's text matches multiple intents, and it's not a clear combined info request, prioritize the most likely intent or return `"intent": "unknown"`.
        If the user's text does not match any of these intents, and is not a confirmation or decline in the current context, return `"intent": "unknown"`.

        User Text: "{user_text}"
        JSON Response:
        """
        try:
            response = model.generate_content(intent_prompt)
            json_string_raw = response.text  # Get raw response first
            json_string = json_string_raw.replace("```json", "").replace(
                "```", "").strip()  # Remove markdown and whitespace
            print(f"Stripped JSON String: {json_string}")  # Debug print
            # Keep raw for comparison
            print(f"LLM Intent JSON (Raw): {json_string_raw}")
            # Parse JSON string to dict
            intent_json = json.loads(json_string)
            return intent_json
        except json.JSONDecodeError as e:
            print(f"JSON Decode Error: {e}, Raw response: {response.text}")
            # No TTS prompt here for unknown, handled in main loop
            return {"intent": "unknown"}
        except Exception as e:
            print(f"LLM Intent Error: {e}")
            # No TTS prompt here for unknown, handled in main loop
            return {"intent": "unknown"}
    else:
        # Basic keyword-based intent for fallback if no Gemini
        user_text_lower = user_text.lower()  # Lowercase once for efficiency
        if "yes" in user_text_lower or "confirm" in user_text_lower or "yep" in user_text_lower or "okay" in user_text_lower or "ok" in user_text_lower or "right" in user_text_lower:
            return {"intent": "confirm"}
        elif "no" in user_text_lower or "decline" in user_text_lower or "nah" in user_text_lower or "cancel" in user_text_lower or "dont confirm" in user_text_lower:
            return {"intent": "decline"}
        elif "directions" in user_text_lower:
            return {"intent": "directions"}
        elif "show directions" in user_text_lower:
            return {"intent": "show_directions"}
        elif "traffic" in user_text_lower and "weather" in user_text_lower:  # Combined intent check
            return {"intent": "combined_info", "parameters": {"intents": ["traffic_info", "weather_info"]}}
        elif "traffic" in user_text_lower:
            return {"intent": "traffic_info"}
        elif "weather" in user_text_lower:
            return {"intent": "weather_info"}
        # Basic ride selection by number (adjust range as needed)
        elif user_text.isdigit() and 1 <= int(user_text) <= 3:
            return {"intent": "show_bookings", "parameters": {"ride_index": int(user_text)}}
        else:
            return {"intent": "unknown", "raw_text": user_text}


# --- Gemini LLM for Enhanced Prompts and Error Handling ---
def generate_tts_with_llm(text_prompt: str) -> str:
    """Generates TTS output using Gemini LLM."""
    if not USE_GEMINI:
        print("Gemini API not configured, using basic TTS prompt.")
        return text_prompt  # Fallback to original text

    try:
        prompt = f"""You are an assistant for a Grab driver.  You are friendly, concise, and helpful.
        Your primary goal is to provide information to the driver using a very concise and clear tone.
        The driver needs to understand all relevant information the first time. Don't show markdown.
        Here is the driver's request: {text_prompt}"""
        response = model.generate_content(prompt)
        llm_generated_text = response.text
        if llm_generated_text:
            print(f"LLM generated TTS prompt: {llm_generated_text}")
            # Check for very short affirmatives (and with punctuation)
            if llm_generated_text.strip().lower() in ["yes", "yep", "okay", "ok", "right", "yes.", "yep.", "okay.", "ok.", "right."]:
                print(
                    "LLM generated a very short affirmative, using a default prompt instead.")
                return "Please specify the ride number or destination."  # More direct prompt
            return llm_generated_text
        else:
            print(
                "LLM did not generate text, using a more informative fallback TTS prompt.")
            return "Please specify the ride number or destination."  # Fallback to direct prompt
    except Exception as e:
        print(f"Error generating TTS prompt with LLM: {e}")
        # Log the specific error
        return text_prompt  # Fallback.


# --- Module Functions ---
# Modified to accept destination, default to Airport
def show_directions(destination="Airport"):
    """Placeholder function to show directions to a destination."""
    tts_prompt = generate_tts_with_llm(f"Showing directions to {destination}.")
    text_to_speech(tts_prompt)  # TTS feedback
    # Console feedback
    print(
        f"Showing directions to {destination} (Placeholder). In a real app, map directions would be displayed.")


# Removed is_retry parameter
# Modified return type to include intent dict
# Modified return type to include intent dict
def ask_user_to_show_bookings(ride_list: List[str]) -> Optional[str or Dict[str, Any]]:
    """Asks the user to choose a ride, handling re-selection correctly."""
    if not ride_list:
        text_to_speech("No rides available. Please check again later.")
        return None

    ride_options_text = "\n".join(
        [f"{i+1}. {ride}" for i, ride in enumerate(ride_list)])

    llm_prompt = f"Ask the driver to choose a ride from the following options: {ride_options_text}."
    tts_prompt = generate_tts_with_llm(llm_prompt)

    retries = 3  # Allow up to 3 retries
    chosen_ride = None  # Initialize outside the loop
    destination_to_ride_index = {}  # Map destination to ride index
    for i, ride in enumerate(ride_list):
        try:
            if ride.startswith("Ride to "):
                # Remove "Ride to " prefix
                ride_no_prefix = ride[len("Ride to "):]
                # Split by " from " to separate destination and origin
                parts_from = ride_no_prefix.split(" from ")
                if len(parts_from) > 1:  # Check if " from " exists
                    # Take everything before " from " as destination
                    destination = parts_from[0].strip()
                # If no " from ", assume the rest is destination (e.g., "Ride to KLIA, RM60")
                else:
                    # Split by comma if no "from" and take first part
                    destination = ride_no_prefix.split(",")[0].strip()

                # Store the FULL destination as extracted, lowercase for matching
                destination_to_ride_index[destination.lower()] = i + 1
        except IndexError as e:
            print(f"Error parsing ride string: {ride}, Error: {e}")
            continue  # Skip this ride if parsing fails

    while retries >= 0 and chosen_ride is None:  # Loop until a valid ride is chosen or retries expire
        text_to_speech(tts_prompt)  # Use text_to_speech (kokoro or fallback)
        context_for_intent = f"The user is choosing a ride from the following options:\n {ride_options_text}. User can say 'number one', 'number two', 'number three' or 'one', 'two', 'three' to choose the ride, or 'show bookings' to see the list again. Or user can say destination name to choose the ride by destination."
        intent_result = speech_to_text_with_intent(
            context_prompt=context_for_intent)

        if intent_result and intent_result["intent"] == "show_bookings":
            # Check if ride_index parameter exists
            if "parameters" in intent_result and "ride_index" in intent_result["parameters"]:
                try:
                    ride_index = intent_result["parameters"].get("ride_index")
                    if ride_index is not None and 1 <= ride_index <= len(ride_list):
                        chosen_ride = ride_list[ride_index - 1]
                        print(f"User chose ride number: {chosen_ride}")
                        return chosen_ride  # Return immediately when ride is chosen
                    else:
                        print("Invalid ride index chosen.")
                        text_to_speech(
                            "Invalid ride number. Please choose from the list.")
                except (KeyError, TypeError):
                    print("Error parsing ride index from intent.")
                    text_to_speech("Please choose the ride number again.")
            elif "parameters" in intent_result and "destination" in intent_result["parameters"]:
                chosen_destination = intent_result["parameters"].get(
                    "destination")
                ride_index_by_destination = destination_to_ride_index.get(
                    chosen_destination.lower())
                if ride_index_by_destination:
                    chosen_ride = ride_list[ride_index_by_destination - 1]
                    print(f"User chose ride by destination: {chosen_ride}")
                    return chosen_ride
                else:
                    print(
                        f"No ride found for destination: {chosen_destination}")
                    text_to_speech(
                        "Sorry, I didn't find a ride for that destination. Please choose by number.")

            else:
                # User just said "show bookings" without specifying index or destination, re-prompt to choose a number
                text_to_speech(
                    "Please choose a ride number or destination from the list.")
                tts_prompt = generate_tts_with_llm(
                    "Please choose a ride number or destination from the list.")

        elif intent_result and intent_result["intent"] == "unknown":
            if "raw_text" in intent_result:
                raw_text = intent_result["raw_text"].lower()
                print(f"Unknown intent, raw user text: {raw_text}")
                for dest_lower, ride_index in destination_to_ride_index.items():
                    # Exact match on lowercased destination
                    if dest_lower == raw_text.strip():  # Check for exact match now
                        chosen_ride = ride_list[ride_index - 1]
                        print(
                            f"Interpreted unknown intent as exact destination selection: {chosen_ride}")
                        return chosen_ride
                    # If exact match fails, you can add fuzzy matching or other logic here if needed, but for now, focusing on exact.
            text_to_speech(
                "Please specify the ride number or destination you're asking about.")

        elif intent_result and intent_result["intent"] == "error":
            # Speech recognition error already handled in speech_to_text_with_intent
            pass
        elif intent_result and intent_result["intent"] == "silence":
            # Do nothing, just listen again in the main loop
            return None
        # Edge case: ignore stray confirms/declines
        elif intent_result and intent_result["intent"] in ["confirm", "decline"]:
            logging.warning(
                f"Ignoring unexpected intent in ride selection: {intent_result['intent']}")
            tts_prompt = generate_tts_with_llm(
                "Please choose a ride number or destination from the list.")  # Re-prompt
        # Edge case: combined info during ride selection (though unlikely)
        elif intent_result and intent_result["intent"] == "combined_info":
            if "parameters" in intent_result and "intents" in intent_result["parameters"]:
                intents = intent_result["parameters"]["intents"]
                if "weather_info" in intents:
                    weather_info_text = get_weather_info()
                    weather_info_prompt = generate_tts_with_llm(
                        weather_info_text)
                    text_to_speech(weather_info_prompt)
                if "traffic_info" in intents:
                    traffic_info_text = get_traffic_info()
                    traffic_info_prompt = generate_tts_with_llm(
                        traffic_info_text)
                    text_to_speech(traffic_info_prompt)
            # tts_prompt = generate_tts_with_llm(
            #     "Please choose a ride number or destination from the list.")  # Re-prompt after info
        # <--- CHECK FOR UNEXPECTED INTENTS
        elif intent_result and intent_result["intent"] not in ["show_bookings", "unknown", "error", "silence", "confirm", "decline", "combined_info"]:
            print(
                f"Unexpected intent during ride selection: {intent_result['intent']}")
            return intent_result  # <--- RETURN THE INTENT DICT
        else:  # Unexpected intent result
            print(
                f"Unexpected intent result during ride selection: {intent_result}")
            text_to_speech(
                "Please choose a ride number or destination from the list.")
            tts_prompt = generate_tts_with_llm(
                # Re-prompt with list context
                "Please choose a ride number or destination from the list.")

        retries -= 1
        if retries >= 0 and chosen_ride is None:  # Only re-prompt if retries left and no ride chosen
            # If not show_bookings, then re-prompt with full list
            if intent_result and intent_result["intent"] != "show_bookings":
                tts_prompt = generate_tts_with_llm(
                    "Please choose a ride from the list again.")  # Re-prompt with list context

    if chosen_ride:
        return chosen_ride
    else:  # Ran out of retries
        # Keep saying this if retries exhausted
        text_to_speech("Sorry, please try again.")
        return None  # Return None if all retries fail


def read_ride_details_and_confirm(ride_details: str) -> bool:
    """Reads ride details and confirms with retry. Handles weather/traffic questions during confirmation."""
    details_text = f"Ride details: {ride_details}."
    llm_prompt = f"Confirm these ride details: {details_text}. Ask if they want to confirm or have questions (weather/traffic)."
    tts_prompt = generate_tts_with_llm(llm_prompt)

    retries = 2
    confirmed = False
    while retries >= 0 and not confirmed:
        text_to_speech(tts_prompt)
        confirmation_intent = speech_to_text_with_intent(
            context_prompt=llm_prompt)

        if confirmation_intent and confirmation_intent["intent"] == "confirm":
            confirmed = True
            break
        elif confirmation_intent and confirmation_intent["intent"] == "decline":
            text_to_speech("Ride declined.")
            return False
        elif confirmation_intent and confirmation_intent["intent"] == "silence":
            pass
        elif confirmation_intent and confirmation_intent["intent"] == "unknown":
            text_to_speech(
                "Please say yes/no to confirm, or ask weather/traffic.")
        elif confirmation_intent and confirmation_intent["intent"] == "error":
            pass
        elif confirmation_intent and confirmation_intent["intent"] == "weather_info":
            weather_info_text = get_weather_info()
            weather_info_prompt = generate_tts_with_llm(weather_info_text)
            text_to_speech(weather_info_prompt)
            # tts_prompt = generate_tts_with_llm(
            #     "Do you want to confirm the ride?")  # Re-prompt
        elif confirmation_intent and confirmation_intent["intent"] == "traffic_info":
            traffic_info_text = get_traffic_info()
            traffic_info_prompt = generate_tts_with_llm(traffic_info_text)
            text_to_speech(traffic_info_prompt)
            # tts_prompt = generate_tts_with_llm(
            #     "Do you want to confirm the ride?")  # Re-prompt
        # Handle combined info request
        elif confirmation_intent and confirmation_intent["intent"] == "combined_info":
            if "parameters" in confirmation_intent and "intents" in confirmation_intent["parameters"]:
                intents = confirmation_intent["parameters"]["intents"]
                if "weather_info" in intents:
                    weather_info_text = get_weather_info()
                    weather_info_prompt = generate_tts_with_llm(
                        weather_info_text)
                    text_to_speech(weather_info_prompt)
                if "traffic_info" in intents:
                    traffic_info_text = get_traffic_info()
                    traffic_info_prompt = generate_tts_with_llm(
                        traffic_info_text)
                    text_to_speech(traffic_info_prompt)
            # tts_prompt = generate_tts_with_llm(
            #     "Do you want to confirm the ride?")  # Re-prompt after combined info
        else:
            text_to_speech(
                "Please say yes/no to confirm, or ask weather/traffic.")

        retries -= 1
        if retries >= 0 and not confirmed:
            tts_prompt_retry = generate_tts_with_llm(
                "Confirm again: yes/no, or ask weather/traffic.")
            text_to_speech(tts_prompt_retry)
        elif retries < 0 and not confirmed:
            text_to_speech("Sorry, please try again later.")
            return False

    return confirmed


def ask_to_show_directions_and_confirm() -> bool:
    """Asks to show directions and confirms with retry."""
    llm_prompt = "Ask the user if they want to see directions for their ride. Phrase it as a clear yes/no question."  # More specific prompt
    tts_prompt = generate_tts_with_llm(llm_prompt)

    retries = 2
    show_directions_confirmed = False
    while retries >= 0 and not show_directions_confirmed:
        text_to_speech(tts_prompt)
        context_for_directions = "Ask user if they want to show directions (yes/no)."
        directions_intent = speech_to_text_with_intent(
            context_prompt=context_for_directions)

        if directions_intent and directions_intent["intent"] == "show_directions":
            # show_directions()
            show_directions_confirmed = True
            break
        elif directions_intent and directions_intent["intent"] == "decline":
            text_to_speech("Directions declined.")
            return False
        elif directions_intent and directions_intent["intent"] == "silence":
            pass
        elif directions_intent and directions_intent["intent"] == "unknown":
            text_to_speech(
                "Do you want to see directions? Please say yes/no.")
        elif directions_intent and directions_intent["intent"] == "error":
            pass
        else:
            text_to_speech(
                "Do you want to see directions? Please say yes/no.")

        retries -= 1
        if retries >= 0 and not show_directions_confirmed:
            tts_prompt_retry = generate_tts_with_llm(
                "Again: Do you want to see directions?")
            text_to_speech(tts_prompt_retry)
        elif retries < 0 and not show_directions_confirmed:
            text_to_speech("Sorry, please try again later.")
            return False

    return show_directions_confirmed


def get_traffic_info():
    """Stub function to get traffic information."""
    return "Traffic is currently light."


def get_weather_info():
    """Stub function to get weather information."""
    return "The weather is sunny and 25 degrees Celsius."


def get_ride_details_from_text(ride_text: str) -> str:
    """Extracts ride details from ride text."""
    parts = ride_text.split(", ")
    if len(parts) >= 2:
        destination = parts[0].replace("Ride to ", "")
        time = parts[1]
        return f"Ride to {destination}, Price: {time}"
    return "Ride details not available."


if __name__ == '__main__':
    try:
        pipeline = KPipeline(lang_code='a')
        initial_greeting_prompt = generate_tts_with_llm(
            "Hello this is Grab Buddy! How can I help you?")
        text_to_speech(initial_greeting_prompt)
    except RuntimeError as e:
        print(f"Kokoro TTS Pipeline likely not initialized in test.")

    print("Grab Driver Buddy Ready! (Ctrl+C to exit)")
    sample_rides = ["Ride to Sunway Universiti from Universiti Tower, RM10",
                    "Ride to KLIA from KLCC, RM60", "Ride to Monash from Sunway Universiti, RM35"]

    last_chosen_destination = None
    ride_confirmed = False

    while True:
        chosen_ride_text = None
        unexpected_intent_result = None
        intent_result_main = speech_to_text_with_intent()

        if intent_result_main and intent_result_main["intent"] == "traffic_info":
            traffic_info = get_traffic_info()
            traffic_info_prompt = generate_tts_with_llm(traffic_info)
            text_to_speech(traffic_info_prompt)
            continue

        elif intent_result_main and intent_result_main["intent"] == "weather_info":
            weather_info_text = get_weather_info()
            weather_info_prompt = generate_tts_with_llm(weather_info_text)
            text_to_speech(weather_info_prompt)
            continue
        # Handle combined info in main loop
        elif intent_result_main and intent_result_main["intent"] == "combined_info":
            if "parameters" in intent_result_main and "intents" in intent_result_main["parameters"]:
                intents = intent_result_main["parameters"]["intents"]
                if "weather_info" in intents:
                    weather_info_text = get_weather_info()
                    weather_info_prompt = generate_tts_with_llm(
                        weather_info_text)
                    text_to_speech(weather_info_prompt)
                if "traffic_info" in intents:
                    traffic_info_text = get_traffic_info()
                    traffic_info_prompt = generate_tts_with_llm(
                        traffic_info_text)
                    text_to_speech(traffic_info_prompt)
            continue  # Continue to next iteration after providing info

        elif intent_result_main and intent_result_main["intent"] == "directions":
            destination_for_directions = last_chosen_destination if last_chosen_destination else "Universiti Malaya Faculty of Computer Science"
            show_directions(destination=destination_for_directions)
            continue

        elif intent_result_main and intent_result_main["intent"] == "unknown":
            print("Unknown intent in main loop.")
            unknown_prompt = generate_tts_with_llm(
                # Changed to specify prompt directly
                "Please specify the ride number or destination you're asking about.")
            # text_to_speech(unknown_prompt)
            continue

        elif intent_result_main and intent_result_main["intent"] == "error":
            print("Speech recognition error in main loop.")
            continue
        elif intent_result_main and intent_result_main["intent"] == "silence":
            print("Silence detected, listening again...")
            continue
        # Edge case handling in main loop
        elif intent_result_main and intent_result_main["intent"] in ["confirm", "decline"]:
            logging.warning(
                f"Ignoring unexpected intent in main loop: {intent_result_main['intent']}")
            continue  # Ignore stray confirms/declines in main loop

        elif not intent_result_main:
            print("No intent result received in main loop.")
            continue

        ride_confirmed = False
        while chosen_ride_text is None and unexpected_intent_result is None:
            booking_result = ask_user_to_show_bookings(
                sample_rides)
            if isinstance(booking_result, dict):
                unexpected_intent_result = booking_result
                break
            else:
                chosen_ride_text = booking_result

            if chosen_ride_text:
                print(f"User's ride choice text: {chosen_ride_text}")
                last_chosen_destination = chosen_ride_text.split(" to ")[1].split(
                    ",")[0]
                break
            else:
                print("No ride chosen, returning to main loop.")
                continue

        if unexpected_intent_result:
            if unexpected_intent_result["intent"] == "weather_info":
                weather_info_text = get_weather_info()
                weather_info_prompt = generate_tts_with_llm(weather_info_text)
                text_to_speech(weather_info_prompt)
                continue
            elif unexpected_intent_result["intent"] == "traffic_info":
                traffic_info = get_traffic_info()
                traffic_info_prompt = generate_tts_with_llm(traffic_info)
                text_to_speech(traffic_info_prompt)
                continue
            elif unexpected_intent_result["intent"] == "directions":
                destination_for_directions = last_chosen_destination if last_chosen_destination else "Universiti Malaya Faculty of Computer Science"
                show_directions(destination=destination_for_directions)
                continue
            else:
                print(
                    f"Unhandled unexpected intent: {unexpected_intent_result['intent']}")
                text_to_speech("Sorry, I cannot do that right now.")
                continue

        if not chosen_ride_text:
            continue

        sample_ride_details = get_ride_details_from_text(chosen_ride_text)
        ride_confirmed = read_ride_details_and_confirm(
            sample_ride_details)
        print(f"Ride confirmed: {ride_confirmed}")

        if not ride_confirmed:
            continue

        show_directions_for_ride = ask_to_show_directions_and_confirm()
        print(f"Show directions (ride related): {show_directions_for_ride}")

        # if show_directions_for_ride:
        #     show_directions()

        final_confirmation_prompt = generate_tts_with_llm(
            "Ride booked. Thank you!")
        text_to_speech(final_confirmation_prompt)
        print("Ride booking flow completed. Listening for next command.\n")
