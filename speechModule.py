import speech_recognition as sr
import google.generativeai as genai
from typing import List, Dict, Optional, Any
import json
from kokoro import KPipeline
import sounddevice as sd
import numpy as np
import pyttsx3  # Import pyttsx3 for fallback TTS
# Corrected imports for Wav2Vec2
from transformers import AutoProcessor, AutoModelForCTC
import sys  # Import sys for graceful exit

# --- Configuration ---
# Removed for security to load via system variable
GOOGLE_API_KEY = "AIzaSyAf8HxoCsImAlgliS43dTaixkIbC6mgR7o"
# GOOGLE_API_KEY = os.environ.get("GOOGLE_API_KEY")  # Secure way, load from environment variable

if not GOOGLE_API_KEY:
    print("Warning: GOOGLE_API_KEY environment variable not set. Gemini API might not work.")
    USE_GEMINI = False  # Disable Gemini usage if key is missing
else:
    USE_GEMINI = True
    genai.configure(api_key=GOOGLE_API_KEY)
    generation_config = genai.GenerationConfig(
        temperature=0.3,  # Lower temperature for more predictable JSON output
        top_p=0.9,
        top_k=20,  # Reduced k for more focused responses
    )
    safety_settings = [
        {"category": "HARM_CATEGORY_HARASSMENT",
            "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
        {"category": "HARM_CATEGORY_HATE_SPEECH",
            "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
        {"category": "HARM_CATEGORY_SEXUALLY_EXPLICIT",
            "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
        {"category": "HARM_CATEGORY_DANGEROUS_CONTENT",
            "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
        {"category": "HARM_CATEGORY_DANGEROUS_CONTENT",
            "threshold": "BLOCK_MEDIUM_AND_ABOVE"},
    ]
    model = genai.GenerativeModel(model_name="gemini-2.0-flash-lite",  # Try newer model
                                  generation_config=generation_config,
                                  safety_settings=safety_settings)

# Initialize kokoro pipeline for TTS
try:
    # 'a' likely means auto-detect language, adjust if needed
    tts_pipeline = KPipeline(lang_code='a')
except Exception as e:
    print(f"Error initializing kokoro TTS pipeline: {e}")
    print("Falling back to basic pyttsx3 TTS. Ensure kokoro and its dependencies are installed correctly.")
    USE_KOKORO_TTS = False
    engine = pyttsx3.init()  # Initialize pyttsx3 as fallback
else:
    USE_KOKORO_TTS = True
    engine = None  # No need for pyttsx3 engine if kokoro is working

# --- Initialize OpenAI Whisper for STT ---
try:
    whisper_processor = AutoProcessor.from_pretrained(
        "mesolitica/wav2vec2-xls-r-300m-mixed")
    whisper_model = AutoModelForCTC.from_pretrained(
        "mesolitica/wav2vec2-xls-r-300m-mixed")
    USE_WHISPER_STT = True
    print("OpenAI Whisper STT initialized.")
except Exception as e:
    print(f"Error initializing OpenAI Whisper: {e}")
    print("Falling back to Google Speech Recognition for STT.")
    USE_WHISPER_STT = False


# --- Text-to-Speech (TTS) ---
def text_to_speech(text: str):
    """Converts text to speech using kokoro (or fallback to pyttsx3)."""
    if USE_KOKORO_TTS:
        try:
            samples_generated = 0
            # To accumulate audio chunks
            full_audio = np.array([], dtype=np.float32)

            # Using 'af_bella' voice as per example
            # Using af_nicole voice. 'af_nicole' voice
            for _, _, audio in tts_pipeline(text, voice='af_nicole'):
                if audio is not None:  # audio could be None if there is an issue
                    samples = audio.shape[0]
                    if samples > 0:  # Ensure audio data is valid
                        samples_generated += samples
                        full_audio = np.concatenate(
                            (full_audio, audio))  # Accumulate audio
                    else:
                        print(
                            "Warning: No audio samples generated by kokoro for this chunk.")
                else:
                    print("Warning: No audio data returned by kokoro for this chunk.")

            if samples_generated == 0:
                print("Error: kokoro TTS pipeline did not generate any audio samples.")
                fallback_tts(text)  # Fallback to pyttsx3 if kokoro fails
            else:
                # --- AUDIO PLAYBACK using sounddevice ---
                # Assuming kokoro samplerate is 24kHz, check kokoro docs
                sd.play(full_audio, samplerate=24000)
                sd.wait()  # Wait until audio finishes playing

        except Exception as e:
            print(f"kokoro TTS Error: {e}")
            print("Falling back to basic pyttsx3 TTS.")
            fallback_tts(text)  # Fallback to pyttsx3 if kokoro fails
    else:
        fallback_tts(text)  # Directly use pyttsx3 if kokoro init failed


def fallback_tts(text: str):
    """Uses pyttsx3 for TTS as a fallback."""
    if engine:  # Check if pyttsx3 engine is initialized
        try:
            engine.say(text)
            engine.runAndWait()
        except Exception as e:
            print(f"Fallback pyttsx3 TTS Error: {e}")
            print("Error with both kokoro and pyttsx3 TTS. Please check your TTS setup.")
    else:
        print("Error: Both kokoro and pyttsx3 TTS failed to initialize.")
        print("Text-to-Speech will not work.")


# --- Speech-to-Text (STT) with LLM Context ---
def speech_to_text_with_intent(context_prompt: str = "") -> Optional[Dict[str, Any]]:
    """
    Captures audio from microphone, converts it to text using Whisper or Google STT,
    and uses LLM to get user intent in JSON format.
    """
    if USE_WHISPER_STT:
        # --- Use Whisper for STT ---
        print("Using OpenAI Whisper for Speech Recognition...")
        samplerate = 16000  # Whisper models were trained on 16kHz audio
        duration = 5  # Maximum recording duration in seconds
        print(f"Listening for {duration} seconds...")
        recording = sd.rec(int(samplerate * duration),
                           samplerate=samplerate, channels=1, dtype='float32')
        sd.wait()  # Wait until recording is finished
        audio_data = np.squeeze(recording)  # Remove single-channel dimension

        input_values = whisper_processor(
            audio_data, sampling_rate=samplerate, return_tensors="pt").input_values
        logits = whisper_model(input_values).logits
        predicted_ids = np.argmax(logits.detach().cpu().numpy(), axis=-1)
        transcription = whisper_processor.batch_decode(
            predicted_ids, skip_special_tokens=True)[0]

        query = transcription
        print(f"Whisper Transcription: {query}")

        if USE_GEMINI:
            language_prompt = f"""Identify the language of the following text.
            The text is transcribed by a speech-to-text model that is trained on Malay, Singlish, and Mandarin primarily, but may also transcribe other languages.
            Just return the language name. If you are unsure, return 'unknown'.

            Text: "{query}"
            Language: """
            try:
                response = model.generate_content(language_prompt)
                detected_language = response.text.strip()
                print(f"Detected Language: {detected_language}")
            except Exception as e:
                print(f"Error detecting language: {e}")
                detected_language = "unknown"  # Default to unknown on error
        else:
            # If no Gemini
            detected_language = "Language detection skipped (Gemini not enabled)."
    else:
        # --- Fallback to Google Speech Recognition ---
        print("Using Google Speech Recognition...")
        r = sr.Recognizer()
        with sr.Microphone() as source:
            print("Listening...")
            audio = r.listen(source)

        try:
            print("Recognizing...")
            # Auto language detection by Google STT
            query = r.recognize_google(audio)
            print(f"Google STT User said: {query}\n")
        except sr.UnknownValueError:
            print("Could not understand audio (Google STT)")
            # Simple error message
            text_to_speech("Sorry, I didn't get you. Please try again.")
            return {"intent": "unknown"}
        except sr.RequestError as e:
            print(
                f"Could not request results from Speech Recognition service (Google STT); {e}")
            # Simple error message
            text_to_speech("Sorry, there was an issue. Please try again.")
            return {"intent": "error"}
        # Assume English if using Google STT as it auto-detects
        detected_language = "English (Google STT)"

    user_text = query.lower()

    if USE_GEMINI:
        intent_prompt = f"""{context_prompt}
        Analyze the following user text and determine the user's intent in the context of a ride booking system for a Grab driver.
        Besides ride booking intents, also consider intents related to traffic and weather information.
        The speech-to-text model used is trained primarily on Malay, Singlish, and Mandarin, so the input text might be in one of these languages or others.
        Return a JSON object with 'intent' and optionally 'parameters'.
        If you cannot determine the intent, set intent to 'unknown'.

        Example Response for ride selection:
        ```json
        {{
          "intent": "choose_ride",
          "parameters": {{
            "ride_index": 1
          }}
        }}
        ```

        Example Response for confirmation:
        ```json
        {{
          "intent": "confirm"
        }}
        ```

        Example Response for declining:
        ```json
        {{
          "intent": "decline"
        }}
        ```

        Example Response for showing directions:
        ```json
        {{
          "intent": "show_directions"
        }}
        ```
        Example Response for requesting traffic information:
        ```json
        {{
          "intent": "traffic_info"
        }}
        ```

        Example Response for requesting weather information:
        ```json
        {{
          "intent": "weather_info"
        }}
        ```


        Example for unknown intent:
        ```json
        {{
          "intent": "unknown"
        }}
        ```

        User Text: "{user_text}"
        JSON Response:
        """
        try:
            response = model.generate_content(intent_prompt)
            json_string_raw = response.text  # Get raw response first
            json_string = json_string_raw.replace("```json", "").replace(
                "```", "").strip()  # Remove markdown and whitespace
            print(f"Stripped JSON String: {json_string}")  # Debug print
            # Keep raw for comparison
            print(f"LLM Intent JSON (Raw): {json_string_raw}")
            # Parse JSON string to dict
            intent_json = json.loads(json_string)
            return intent_json
        except json.JSONDecodeError as e:
            print(f"JSON Decode Error: {e}, Raw response: {response.text}")
            # Simple error message
            text_to_speech("Sorry, I didn't get you. Please try again.")
            # Return unknown intent on json decode fail
            return {"intent": "unknown"}
        except Exception as e:
            print(f"LLM Intent Error: {e}")
            # Simple error message
            text_to_speech("Sorry, I didn't get you. Please try again.")
            # Return unknown intent on LLM error
            return {"intent": "unknown"}
    else:
        # Basic keyword-based intent for fallback if no Gemini
        if "yes" in user_text or "confirm" in user_text or "yep" in user_text:
            return {"intent": "confirm"}
        elif "no" in user_text or "decline" in user_text or "nah" in user_text:
            return {"intent": "decline"}
        elif "directions" in user_text or "show" in user_text:
            return {"intent": "show_directions"}
        elif "traffic" in user_text:
            return {"intent": "traffic_info"}
        elif "weather" in user_text:
            return {"intent": "weather_info"}
        else:
            # Return raw text for unknown intent
            return {"intent": "unknown", "raw_text": user_text}


# --- Gemini LLM for Enhanced Prompts and Error Handling ---
def generate_tts_with_llm(text_prompt: str) -> str:
    """Generates TTS output using Gemini LLM."""
    if not USE_GEMINI:
        print("Gemini API not configured, using basic TTS prompt.")
        return text_prompt  # Fallback to original text

    try:
        prompt = f"""You are an assistant for a Grab driver.  You are friendly, concise, and helpful.
        Your primary goal is to provide information to the driver using a very concise and clear tone.
        The driver needs to understand all relevant information the first time. Don't show markdown.
        Here is the prompt: {text_prompt}"""  # Universal system prompt
        response = model.generate_content(prompt)
        llm_generated_text = response.text
        if llm_generated_text:
            print(f"LLM generated TTS prompt: {llm_generated_text}")
            return llm_generated_text
        else:
            print("LLM did not generate text, using basic TTS prompt.")
            return text_prompt
    except Exception as e:
        print(f"Error generating TTS prompt with LLM: {e}")
        # Log the specific error
        return text_prompt  # Fallback.


def generate_user_friendly_error(error_type: str) -> str:
    """Generates a user-friendly error message using Gemini"""
    if not USE_GEMINI:
        return "Sorry, I encountered a problem."

    error_prompts = {
        "speech_recognition_error": "Craft a brief and polite error message for the user to inform them that the speech recognition service is temporarily unavailable.  Suggest they try again later.",
        "speech_recognition_unknown": "Generate a brief and friendly message to tell the user the system did not understand the audio.  Encourage them to speak more clearly.",
        "general_error": "Provide a general, helpful error message to the user to indicate that an unexpected problem has occurred.",
        "no_rides": "Inform the driver that no rides are currently available. Apologize briefly and suggest checking again later.",
        "ride_declined": "Acknowledge that the driver declined the ride.  Inform them that you have noted their decision and will notify them of new requests.",  # Updated decline message
        "directions_declined": "Acknowledge that the driver declined to show directions. Proceed without showing directions."
        # Add other error types as needed
    }
    prompt = f"""You are an assistant providing informative and helpful messages.
    Generate a very concise and informative user-friendly error message. The error is: {error_prompts.get(error_type, 'An unknown error occurred.')}"""  # Universal system prompt

    try:
        response = model.generate_content(prompt)
        error_message = response.text.strip()
        print(f"Generated error message: {error_message}")
        return error_message
    except Exception as e:
        print(f"Error generating error message with Gemini: {e}")
        return "Sorry, I encountered an error."

# --- Module Functions ---


def ask_user_to_choose_ride(ride_list: List[str]) -> Optional[str]:
    """Asks the user to choose a ride with retry on failure."""
    if not ride_list:
        text_to_speech(generate_user_friendly_error("no_rides"))
        return None

    ride_options_text = "\n".join(
        [f"{i+1}. {ride}" for i, ride in enumerate(ride_list)])
    llm_prompt = f"Ask the driver to choose one of these rides. The ride options are: {ride_options_text}."
    tts_prompt = generate_tts_with_llm(llm_prompt)

    retries = 2  # Allow up to 2 retries
    chosen_ride = None  # Initialize outside the loop
    while retries >= 0:
        text_to_speech(tts_prompt)  # Use text_to_speech (kokoro or fallback)
        context_for_intent = "The user is choosing a ride from the following options:\n" + ride_options_text
        intent_result = speech_to_text_with_intent(
            context_prompt=context_for_intent)

        if intent_result and intent_result["intent"] == "choose_ride":
            try:
                ride_index = intent_result["parameters"].get("ride_index")
                if ride_index is not None and 1 <= ride_index <= len(ride_list):
                    chosen_ride = ride_list[ride_index - 1]
                    print(f"User chose ride: {chosen_ride}")
                    return chosen_ride  # Return immediately when ride is chosen
                else:
                    print("Invalid ride index chosen.")
                    text_to_speech(
                        "Sorry, that is not a valid ride number. Please choose again.")
            except (KeyError, TypeError):
                print("Error parsing ride index from intent.")
                # Simpler retry prompt
                text_to_speech("Sorry, please choose a ride number again.")
        elif intent_result and intent_result["intent"] == "unknown":
            if "raw_text" in intent_result:
                print(
                    f"Unknown intent, raw user text: {intent_result['raw_text']}")
            # Simpler retry prompt
            text_to_speech("Sorry, I didn't get you. Please try again.")
        elif intent_result and intent_result["intent"] == "error":
            # Speech recognition error already handled in speech_to_text_with_intent
            pass  # Error message already spoken
        else:
            print(f"Unexpected intent result: {intent_result}")
            # Simpler retry prompt
            text_to_speech("Sorry, I missed that. Could you please try again?")

        # Retry if not successful
        if intent_result and intent_result["intent"] != "choose_ride":
            retries -= 1
            if retries >= 0:
                text_to_speech("Let's try again.")  # Prompt to try again
            else:
                # Give up after retries
                text_to_speech(
                    "Sorry, I'm having trouble understanding. Let's move on.")
                return None  # Exit after retries
        else:
            return chosen_ride  # Return if ride is chosen

    return None  # Return None if all retries fail


# Removed weather_info
def read_ride_details_and_confirm(ride_details: str) -> bool:
    """Reads ride details and confirms with retry."""
    details_text = f"Ride details: {ride_details}."  # Removed weather info from text
    # Removed weather info from prompt
    llm_prompt = f"Confirm the ride details with the driver. The details are: {details_text}. Ask if they want to confirm. Don't show markdown."
    tts_prompt = generate_tts_with_llm(llm_prompt)

    retries = 2  # Allow up to 2 retries
    while retries >= 0:
        text_to_speech(tts_prompt)  # Use text_to_speech (kokoro or fallback)
        context_for_confirmation = "The user is being asked to confirm ride details."
        confirmation_intent = speech_to_text_with_intent(
            context_prompt=context_for_confirmation)

        if confirmation_intent and confirmation_intent["intent"] == "confirm":
            return True
        elif confirmation_intent and confirmation_intent["intent"] == "decline":
            text_to_speech(generate_user_friendly_error(
                "ride_declined"))  # Uses updated decline message
            return False
        elif confirmation_intent and confirmation_intent["intent"] == "unknown":
            text_to_speech(
                # More direct retry prompt
                "Please confirm if you want to proceed with this ride by saying yes or no.")
        elif confirmation_intent and confirmation_intent["intent"] == "error":
            # Speech recognition error already handled in speech_to_text_with_intent
            pass  # Error message already spoken
        else:  # unexpected intent
            text_to_speech(
                # More direct retry prompt
                "Sorry, I didn't understand. Please say yes to confirm or no to decline.")

        # Retry if not successful
        if confirmation_intent and confirmation_intent["intent"] not in ["confirm", "decline"]:
            retries -= 1
            if retries >= 0:
                text_to_speech("Let's try again.")  # Prompt to try again
            else:
                # Give up after retries, skip confirmation
                text_to_speech("Okay, we will skip ride confirmation.")
                return False  # Default to not confirmed after retries
        else:
            # Exit loop if confirmed or declined
            return confirmation_intent["intent"] == "confirm"

    return False  # Default to not confirmed if all retries fail


def ask_to_show_directions_and_confirm() -> bool:
    """Asks to show directions and confirms with retry."""
    llm_prompt = "Ask the driver if they want to show directions."
    tts_prompt = generate_tts_with_llm(llm_prompt)

    retries = 2  # Allow up to 2 retries
    while retries >= 0:
        text_to_speech(tts_prompt)  # Use text_to_speech (kokoro or fallback)
        context_for_directions = "The user is being asked if they want to show directions."
        directions_intent = speech_to_text_with_intent(
            context_prompt=context_for_directions)

        if directions_intent and directions_intent["intent"] == "show_directions":
            text_to_speech("Showing directions")
            return True
        elif directions_intent and directions_intent["intent"] == "decline":
            text_to_speech(generate_user_friendly_error("directions_declined"))
            return False
        elif directions_intent and directions_intent["intent"] == "unknown":
            text_to_speech(
                # More direct retry prompt
                "Please say yes if you want to see directions or no to continue without directions.")
        elif directions_intent and directions_intent["intent"] == "error":
            # Speech recognition error already handled in speech_to_text_with_intent
            pass  # Error message already spoken
        else:  # unexpected intent
            text_to_speech(
                # More direct retry prompt
                "Sorry, I didn't understand. Please indicate if you want to show directions.")

        # Retry if not successful
        if directions_intent and directions_intent["intent"] not in ["show_directions", "decline"]:
            retries -= 1
            if retries >= 0:
                text_to_speech("Let's try again.")  # Prompt to try again
            else:
                # Give up after retries, skip directions
                text_to_speech("Okay, proceeding without showing directions.")
                return False  # Default to no directions after retries
        else:
            # Exit loop if show_directions or declined
            return directions_intent["intent"] == "show_directions"

    return False  # Default to no directions if all retries fail

# --- Helper functions for traffic and weather (stubs) ---


def get_traffic_info():
    """Stub function to get traffic information."""
    # In a real application, this would fetch traffic data
    return "Traffic is currently light."


def get_weather_info():
    """Stub function to get weather information."""
    # In a real application, this would fetch weather data
    return "The weather is sunny and 25 degrees Celsius."


# --- Helper function to extract ride details from ride text (for testing) ---
def get_ride_details_from_text(ride_text: str) -> str:
    """
    Extracts ride details from ride text. (Simple implementation for testing)
    In real app, you would likely fetch details from a structured source.
    """
    parts = ride_text.split(", ")
    if len(parts) >= 2:
        destination = parts[0].replace("Ride to ", "")  # e.g., "Airport"
        time = parts[1]  # e.g., "8 AM"
        # Basic details
        return f"Ride to {destination}, Driver: John, Car: Sedan, ETA: {time}"
    return "Ride details not available."  # Default if parsing fails


if __name__ == '__main__':
    try:
        pipeline = KPipeline(lang_code='a')  # kokoro time example
        # kokoro time example
        text_to_speech(
            "Hello Kokoro TTS is working")
    except RuntimeError as e:
        print(f"Kokoro TTS Pipeline likely not initialized in test.")

    print("Speech Module Test: (Press Ctrl+C to exit)")
    sample_rides = ["Ride to Airport at 8 AM, $25",
                    "Ride to Downtown at 9 AM, $30", "Ride to Beach at 10 AM, $35"]

    while True:  # Main loop for continuous listening
        chosen_ride_text = None
        # No context prompt for main loop
        intent_result_main = speech_to_text_with_intent()

        if intent_result_main and intent_result_main["intent"] == "traffic_info":
            traffic_info = get_traffic_info()  # Call stub function
            text_to_speech(traffic_info)
            continue  # Continue to next iteration of loop

        elif intent_result_main and intent_result_main["intent"] == "weather_info":
            weather_info_text = get_weather_info()  # Call stub function
            text_to_speech(weather_info_text)
            continue  # Continue to next iteration of loop

        elif intent_result_main and intent_result_main["intent"] == "unknown":
            print("Unknown intent in main loop.")
            continue  # Continue to next iteration of loop

        elif intent_result_main and intent_result_main["intent"] == "error":
            print("Speech recognition error in main loop.")
            continue  # Continue to next iteration of loop
        elif not intent_result_main:
            print("No intent result received in main loop.")
            continue  # Continue to next iteration of loop

        # --- Ride booking flow if not traffic/weather ---
        while chosen_ride_text is None:  # Loop until a valid ride is chosen
            chosen_ride_text = ask_user_to_choose_ride(sample_rides)
            if chosen_ride_text:
                print(f"User's ride choice text: {chosen_ride_text}")
                break  # Exit loop if valid ride is chosen
            else:
                print("No ride chosen, returning to main loop.")
                continue  # Back to main loop if no ride chosen

        if not chosen_ride_text:  # In case ask_user_to_choose_ride returned None or loop continued
            continue  # Go back to main listening loop

        # --- UPDATED: Dynamically generate sample_ride_details ---
        sample_ride_details = get_ride_details_from_text(chosen_ride_text)

        # Test 2: Read ride details and confirm (weather info removed)
        ride_confirmed = read_ride_details_and_confirm(
            sample_ride_details)  # Removed weather_info
        print(f"Ride confirmed: {ride_confirmed}")

        if not ride_confirmed:  # If ride not confirmed, go back to main loop
            continue

        # Test 3: Ask to show directions
        show_directions = ask_to_show_directions_and_confirm()
        print(f"Show directions: {show_directions}")

        # Confirmation at end of flow
        text_to_speech("Ride booked. Thank you!")
        # Indicate loop restart
        print("Ride booking flow completed. Listening for next command.\n")
